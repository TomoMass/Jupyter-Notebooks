{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anaconda3下でのInstall\n",
    "\n",
    "condaではtensorboard実行に問題が出たので一旦これで。\n",
    "\n",
    "```\n",
    "$ pip install -i https://pypi.anaconda.org/jjhelmus/simple tensorflow\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hi, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant('Hi, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlowを簡単な計算で理解する\n",
    "\n",
    "> [TensorFlowを算数で理解する - Qiita](http://qiita.com/icoxfog417/items/fb5c24e35a849f8e2c5d)\n",
    "\n",
    "### スカラ量で計算してみる\n",
    "\n",
    "- 計算する数式\n",
    "$$ \n",
    "y = x^2 + b\n",
    "$$\n",
    "\n",
    "\n",
    "- flowを図示すると\n",
    "\n",
    "```\n",
    "0.5 --> x--[square]--[add]--> result\n",
    "                      |\n",
    "3.0 --> b-------------+\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.25]\n"
     ]
    }
   ],
   "source": [
    "def x2_plus_b(x, b):\n",
    "    _x = tf.constant(x)\n",
    "    _b = tf.constant(b)\n",
    "    result = tf.square(_x)\n",
    "    result = tf.add(result, _b)\n",
    "    return result\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run([x2_plus_b(.5,3.)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoardによる可視化\n",
    "\n",
    "- 実行後に、コマンドラインから下記を実行\n",
    " \n",
    " ```\n",
    "$ tensorboard --logdir=/path/to/log-directory\n",
    " ```\n",
    "\n",
    "- `http://0.0.0.0:6006`にアクセスする\n",
    "\n",
    "- `GRAPH`に実行済フローが複数表示される\n",
    "\n",
    "> ポイントとしては、`tf.scalar_summary`で計算した値をsummaryしておく点です。こうして計算したsummaryを、`tf.train.SummaryWriter`で書き出していきます。 http://qiita.com/icoxfog417/items/fb5c24e35a849f8e2c5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def monitor_calculation(x, b):\n",
    "    title = \"b = {0}\".format(b)\n",
    "    c = x2_plus_b(float(x), float(b))\n",
    "    s = tf.scalar_summary(title, c)\n",
    "    m = tf.merge_summary([s])  # if you are using some summaries, merge them\n",
    "    return m\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.train.SummaryWriter(\"log\", graph_def=sess.graph_def)    \n",
    "    xaxis = range(-10, 12)\n",
    "\n",
    "    for b in range(3):\n",
    "        for x in xaxis:\n",
    "            summary_str = sess.run(monitor_calculation(x, b))\n",
    "            writer.add_summary(summary_str, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スカラ量で計算する\n",
    "\n",
    "> https://www.tensorflow.org/versions/master/get_started/index.html\n",
    "\n",
    "上記コードはPython2ベースのため、`xrange()` -> `range()`に修正。\n",
    "\n",
    "> 参考 http://stackoverflow.com/questions/17192158/nameerror-global-name-xrange-is-not-defined-in-python-3\n",
    "\n",
    "- やっていることは回帰分析\n",
    "\n",
    "> 「y = 0.1 x + 0.3」という数式を使って生成したxとyを学習データとして、y = W x + b という数式のWとbを最適化していく http://qiita.com/MATS_ELB/items/dfc50149d52e47e5a07b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.07575795] [ 0.5411855]\n",
      "20 [ 0.02578249] [ 0.33941314]\n",
      "40 [ 0.07675866] [ 0.31234229]\n",
      "60 [ 0.09272193] [ 0.30386502]\n",
      "80 [ 0.09772088] [ 0.30121034]\n",
      "100 [ 0.09928628] [ 0.30037904]\n",
      "120 [ 0.0997765] [ 0.30011871]\n",
      "140 [ 0.09993] [ 0.30003718]\n",
      "160 [ 0.09997807] [ 0.30001166]\n",
      "180 [ 0.09999313] [ 0.30000365]\n",
      "200 [ 0.09999785] [ 0.30000114]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンソルで計算する\n",
    "\n",
    "> http://qiita.com/MATS_ELB/items/fec7f54de2dd18b043ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.12049839  0.63580847]\n",
      " [ 0.7111249  -0.02813603]] [ 0.05483134  0.09086838]\n",
      "100 [[ 0.15628858  0.04232659]\n",
      " [ 0.05392477  0.14043736]] [ 0.27025187  0.27766153]\n",
      "200 [[ 0.10838222  0.00629473]\n",
      " [ 0.00802105  0.10602347]] [ 0.29557258  0.29667521]\n",
      "300 [[ 0.10124753  0.00093688]\n",
      " [ 0.00119379  0.10089649]] [ 0.29934105  0.29950514]\n",
      "400 [[ 0.10018568  0.00013946]\n",
      " [ 0.0001777   0.10013343]] [ 0.29990193  0.29992634]\n",
      "500 [[  1.00027628e-01   2.07803114e-05]\n",
      " [  2.64537048e-05   1.00019872e-01]] [ 0.29998541  0.29998901]\n",
      "600 [[  1.00004129e-01   3.12404495e-06]\n",
      " [  3.96192627e-06   1.00002974e-01]] [ 0.29999781  0.29999834]\n",
      "700 [[  1.00000627e-01   5.01336388e-07]\n",
      " [  6.14700070e-07   1.00000471e-01]] [ 0.29999965  0.29999974]\n",
      "800 [[  1.00000247e-01   2.22809277e-07]\n",
      " [  2.17059082e-07   1.00000232e-01]] [ 0.29999986  0.29999986]\n",
      "900 [[  1.00000247e-01   2.22755844e-07]\n",
      " [  2.14493255e-07   1.00000232e-01]] [ 0.29999986  0.29999986]\n",
      "1000 [[  1.00000247e-01   2.22767198e-07]\n",
      " [  2.14479655e-07   1.00000232e-01]] [ 0.29999986  0.29999986]\n"
     ]
    }
   ],
   "source": [
    "# tfという名前で参照できるようにtensorflowを、npという名前で参照できるようにインポート\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# y_data = W_data * x_data + b_data というx_dataとy_dataの関係になるようにあらかじめ\n",
    "# W_dataとb_dataの値を定める。機械学習が適切に行われるとWはこのW_dataに、bはこのb_dataに近づく\n",
    "# なお、W_dataは２行２列のテンソル、b_dataは２行１列のテンソル\n",
    "W_data = np.array([[0.1, 0], [0, 0.1]])\n",
    "b_data = np.array([0.3, 0.3])\n",
    "\n",
    "# 乱数生成を利用して0から1の間の数値を持つ２行１列の行列「X_data」を浮動小数として100個生成\n",
    "x_data = np.random.rand(100, 2, 1).astype(\"float32\")\n",
    "\n",
    "# その後で、生成した100個のxに対して、行列版でのy=0.1x+0.3となるようなyを100個生成\n",
    "y_data = W_data * x_data + b_data\n",
    "\n",
    "# 上記で生成したxとy（共に２行１列のテンソル）の組を学習データとして用いる\n",
    "\n",
    "# 機械学習で最適化するWとbを設定する。Wは２行２列のテンソル。bは２行１列のテンソル。\n",
    "W = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# 学習において、その時点での学習のダメ程度を表すlossを、学習データのyとその時点でのyの差の２乗と定義\n",
    "# Wとbの最適化のアルゴリズムを最急降下法（勾配法）とし、その１回の最適化処理にoptimizerと名前を付ける\n",
    "# 上記の最適化処理の繰り返しによりlossを最小化する処理をtrainと呼ぶことにする\n",
    "loss = tf.reduce_mean(tf.square(y_data - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 学習を始める前にこのプログラムで使っている変数を全てリセットして空っぽにする\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.（おきまりの文句）\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 学習を1000回行い、100回目ごとに画面に学習回数とWとbのその時点の値を表示する\n",
    "for step in range(1001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "\n",
    "# Learns best fit is W: [[0.1, 0], [0, 0.1]], b: [0.3, 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次は同内容のTensorboard可視化（エラーあり）\n",
    "\n",
    "> http://qiita.com/MATS_ELB/items/fec7f54de2dd18b043ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tfという名前で参照できるようにtensorflowを、npという名前で参照できるようにインポート\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# y_data = W_data * x_data + b_data というx_dataとy_dataの関係になるようにあらかじめ\n",
    "# W_dataとb_dataの値を定める。機械学習が適切に行われるとWはこのW_dataに、bはこのb_dataに近づく\n",
    "# なお、W_dataは２行２列のテンソル、b_dataは２行１列のテンソル\n",
    "W_data = np.array([[0.1, 0], [0, 0.1]])\n",
    "b_data = np.array([0.3, 0.3])\n",
    "\n",
    "# 乱数生成を利用して0から1の間の数値を持つ２行１列の行列「X_data」を浮動小数として100個生成\n",
    "x_data = np.random.rand(100, 2, 1).astype(\"float32\")\n",
    "\n",
    "# その後で、生成した100個のxに対して、行列版でのy=0.1x+0.3となるようなyを100個生成\n",
    "y_data = W_data * x_data + b_data\n",
    "\n",
    "# 上記で生成したxとy（共に２行１列のテンソル）の組を学習データとして用いる\n",
    "\n",
    "# 機械学習で最適化するWとbを設定する。Wは２行２列のテンソル。bは２行１列のテンソル。\n",
    "W = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = W * x_data + b\n",
    "\n",
    "## TensorBoardへ表示するための変数を用意する（ヒストグラム用）\n",
    "W_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)\n",
    "\n",
    "# 学習において、その時点での学習のダメ程度を表すlossを、学習データのyとその時点でのyの差の２乗と定義\n",
    "# Wとbの最適化のアルゴリズムを最急降下法（勾配法）とし、その１回の最適化処理にoptimizerと名前を付ける\n",
    "# 上記の最適化処理の繰り返しによりlossを最小化する処理をtrainと呼ぶことにする\n",
    "loss = tf.reduce_mean(tf.square(y_data - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "## TensorBoardへloss（学習のダメ具合の指標として設定したスカラー値）を表示するための変数を用意する（イベント用）\n",
    "loss_sum = tf.scalar_summary(\"loss\", loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 上記で用意した合計４つのTensorBoard描画用の変数を、TensorBoardが利用するSummaryデータとしてmerge（合体）する\n",
    "# また、そのSummaryデータを書き込むSummaryWriterを用意し、書き込み先を'/tmp/tf_logs'ディレクトリに指定する\n",
    "merged = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter(\"/tmp/tf_logs\", sess.graph_def)\n",
    "\n",
    "\n",
    "# 学習を始める前にこのプログラムで使っている変数を全てリセットして空っぽにする\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.（おきまりの文句）\n",
    "sess.run(init)\n",
    "\n",
    "# 学習を1000回行い、10回目ごとにSummaryデータを保存し、画面にWとbのその時点の値を表示する\n",
    "for step in range(1001):\n",
    "    if step % 10 == 0:\n",
    "        result = sess.run([merged, loss])\n",
    "        summary_str = result[0]\n",
    "        writer.add_summary(summary_str, step)\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "    else:\n",
    "        sess.run(train)\n",
    "\n",
    "# Learns best fit is W: [[0.1, 0], [0, 0.1]], b: [0.3, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow公式レポジトリを使う\n",
    "\n",
    "### git cloneする\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/tensorflow/tensorflow\n",
    "```\n",
    "\n",
    "`/tensorflow/tensorflow/examples`にtutorials等のsource codeあり。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
